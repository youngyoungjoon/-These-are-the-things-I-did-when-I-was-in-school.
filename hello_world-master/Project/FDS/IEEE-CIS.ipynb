{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 온라인 거래 데이터를 활용한 이상거래 탐지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 비지도학습- 랜덤포레스트와 DNN을 통해 이상거래 탐지 모형 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c12c07c75d93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터의 경우  identity와 transaction인 두 파일로 나눠짐\n",
    "    모든 거래 데이터가 해당 ID를 가지고 있는 것은 아님=>TransactionID로 join\n",
    "    \n",
    "> train_transaction, train_identity, test_transaction, test_identity\n",
    "\n",
    "* Transaction의 변수 \n",
    "    * ProductCD\n",
    "    * emaildomain\n",
    "    * card1-card6\n",
    "    * addr1, addr2\n",
    "    * P_emaildomain\n",
    "    * M1 - M9\n",
    "\n",
    "\n",
    "* Identity의 변수\n",
    "    * DeviceType\n",
    "    * Deviceinfo\n",
    "    * id_12 - id_38\n",
    "\n",
    "* 각 변수들은 범주형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 두 파일을 합쳐 train, test 데이터로 사용하고자 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\USER\\20190722_아시아 경제 update\\notebook\\CopyProject\")\n",
    "train_transaction = pd.read_csv('train_transaction.csv', \n",
    "                                  index_col = 'TransactionID' )\n",
    "train_identity = pd.read_csv('train_identity.csv', index_col = 'TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transaction = pd.read_csv('test_transaction.csv', index_col = \"TransactionID\")\n",
    "test_identity = pd.read_csv('test_identity.csv', index_col = \"TransactionID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_transaction.merge(train_identity, how = 'left', left_index =True,\n",
    "                                    right_index = True)\n",
    "test = test_transaction.merge(test_identity, how = 'left', left_index =True,\n",
    "                                 right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['isFraud']\n",
    "X_train = train.drop(columns=['isFraud'])\n",
    "X_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del train_transaction, train_identity, test_transaction, test_identity, train, test\n",
    "# 한번만 run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TransactionDT 변수는 주어진 참조 날짜 시간이며, 실제 time-stamp가 아님\n",
    "    따라서 위의 변수를 제거하고자 함"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train = X_train.drop('TransactionDT', axis=1)\n",
    "X_test = X_test.drop('TransactionDT', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ◎ 결측치 및 쓸모 없는 변수 제거 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.isnull().sum(axis=0) 의 경우 중간생략으로 알 수 없는 컬럼이 많음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_columns = [x for x in X_train.columns \n",
    "                if (X_train[x].isnull().sum(axis=0) / X_train.shape[0]) > 0.97 ]\n",
    "na_columns_test = [x for x in X_test.columns \n",
    "                  if (X_test[x].isnull().sum(axis=0) / X_test.shape[0]) > 0.07 ]\n",
    "# NaN 비율이 97% 이상인 열이면 제거 (임의의 비율)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_drop = list(set(na_columns + na_columns_test))\n",
    "len(columns_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns_drop, axis = 1)\n",
    "X_test = X_test.drop(columns_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [x for x in X_train.columns if x[0] == \"V\"]\n",
    "X_train = X_train.drop(drop_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_drop = ['C1', 'C2','C5','C6','C9','C11', 'C14']\n",
    "X_train = X_train.drop(c_drop, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(drop_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(c_drop, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 변수의 고유한 값 중 하나의 값에만 치우쳐져 있는 경우 분석의 결과를 왜곡시킬 수 있음\n",
    "* 쓸모없는 변수라 판단하고 제거함"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# feature에서 한 값의 비율이 90%이상인 열을 제거 \n",
    "# NaN값을 포함하여 변수 고유한 값들의 상대비율을 구함\n",
    "\n",
    "nan_columns = [x for x in X_train.columns \n",
    "                      if X_train[x].value_counts(dropna=False, normalize=True).values[0] > 0.90]\n",
    "nan_columns_test = [x for x in X_test.columns \n",
    "                             if X_test[x].value_counts(dropna=False, normalize=True).values[0] > 0.90]\n",
    "cols_to_drop = list(set(nan_columns + nan_columns_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train = X_train.drop(cols_to_drop, axis=1)\n",
    "X_test = X_test.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 인코딩 : Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "for f in X_train.columns:\n",
    "    if X_train[f].dtype=='object' or X_test[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(X_train[f].values) + list(X_test[f].values))\n",
    "        X_train[f] = lbl.transform(list(X_train[f].values))\n",
    "        X_test[f] = lbl.transform(list(X_test[f].values)) \n",
    "        \n",
    "X_train = X_train.fillna(-999)\n",
    "X_test = X_test.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe() #TransactionAmt, card1, card2 - log변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['TransactionAmt'] = np.log(X_train['TransactionAmt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['card2'] = np.log(X_train['card2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer, MinMaxScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMscaler = MinMaxScaler()\n",
    "X_test['card3'] = MMscaler.fit_transform(X_test[['card3']])\n",
    "X_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMscaler = MinMaxScaler()\n",
    "X_test['card5'] = MMscaler.fit_transform(X_test[['card5']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMscaler = MinMaxScaler()\n",
    "X_test['C4'] = MMscaler.fit_transform(X_test[['C4']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMscaler = MinMaxScaler()\n",
    "X_test['C7'] = MMscaler.fit_transform(X_test[['C7']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMscaler = MinMaxScaler()\n",
    "X_test['C8'] = MMscaler.fit_transform(X_test[['C8']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMscaler = MinMaxScaler()\n",
    "X_test['C10'] = MMscaler.fit_transform(X_test[['C10']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMscaler = MinMaxScaler()\n",
    "X_test['C12'] = MMscaler.fit_transform(X_test[['C12']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMscaler = MinMaxScaler()\n",
    "X_test['C13'] = MMscaler.fit_transform(X_test[['C13']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMscaler = MinMaxScaler()\n",
    "X_test['D1'] = MMscaler.fit_transform(X_test[['D1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMscaler = MinMaxScaler()\n",
    "X_test['D10'] = MMscaler.fit_transform(X_test[['D10']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMscaler = MinMaxScaler()\n",
    "X_test['D15'] = MMscaler.fit_transform(X_test[['D15']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 데이터 용량이 커서 돌아가는데 시간이 많이 걸림\n",
    "* 메모리를 줄일 필요를 느낌 - kaggle의 reduce-mem-usage함수를 찾아봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# From kernel https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "# WARNING! THIS CAN DAMAGE THE DATA \n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "X_train = reduce_mem_usage(X_train)\n",
    "X_test = reduce_mem_usage(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 불러오기 시간을 줄이기 위해 메모리 줄인 데이터 저장\n",
    "* 다음 부터는 이 데이터를 불러와서 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(\"X_test.csv\", header = True, index = True)\n",
    "X_train.to_csv(\"X_train.csv\", header = True, index = True)\n",
    "#y_train.to_csv(\"y_train.csv\", header = True, index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 탐색 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\Woodayoung\\Desktop\\Datastudy\\asiae\\data1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train.csv', index_col = \"TransactionID\")\n",
    "y_train = pd.read_csv('y_train.csv', index_col = \"TransactionID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = X_train.copy()\n",
    "train1['isFraud'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사기/ 비사기 도수 분포표\n",
    "sns.countplot('isFraud', data = train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts(normalize=True) # evnet rate : about 3.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 데이터의 불균형을 줄이면서 , 메모리 부족 문제를 해결하기 위해 Random Under-Sampling을 하기로 결정\n",
    "    * 각자 다른 사양의 노트북을 사용하여 메모리 부족 문제가 심각\n",
    "    \n",
    "    \n",
    "* 랜덤으로 삭제하기 때문에 표본에 따른 부정확한 결과가 나올 수 도 있음을 인지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=X_train.card2.isnull()\n",
    "X_train.card2[i] = 5.768366"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a, y_train_a = RandomUnderSampler(random_state=0).fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사기와 비사기의 비율을 1대1로 맞춰줌\n",
    "sns.countplot(y_train_a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TransactionAmt 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a = pd.DataFrame(X_train_a, columns = header)\n",
    "y_train_a = pd.Series(y_train_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aa = X_train_a.copy()\n",
    "X_train_aa['isFraud'] = y_train_a\n",
    "train_a = X_train_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot('isFraud', 'TransactionAmt', data = train_a , notch = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = train_a[['isFraud']].copy()\n",
    "df_temp['TransactionAmtc'] = pd.qcut(train_a.TransactionAmt,7)\n",
    "sns.barplot(x='TransactionAmtc',y='isFraud', data=df_temp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ProductCD 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a.ProductCD.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot('isFraud', data = train_a, hue = 'ProductCD')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='ProductCD', y='isFraud', data= train_a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a.head(3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in train_a :\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X_train_a.C1.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = train.loc[train['isFraud'] == 1]\n",
    "train_0 = train.loc[train['isFraud'] == 0]\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 8))\n",
    "train_1.groupby('card1')['card1'].count().plot(kind='barh', ax=ax1, title='Count of card1 fraud')\n",
    "train_0.groupby('card1')['card1'].count().plot(kind='barh', ax=ax2, title='Count of card1 non-fraud')\n",
    "plt.ax2.set_ylim([0, 800])\n",
    "train_1.groupby('card2')['card2'].count().plot(kind='barh', ax=ax3, title='Count of card2 fraud')\n",
    "train_0.groupby('card2')['card2'].count().plot(kind='barh', ax=ax4, title='Count of card2 non-fraud')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 8))\n",
    "train_1.groupby('card3')['card3'].count().plot(kind='barh', ax=ax1, title='Count of card3 fraud')\n",
    "train_0.groupby('card3')['card3'].count().plot(kind='barh', ax=ax2, title='Count of card3 non-fraud')\n",
    "train_1.groupby('card4')['card4'].count().plot(kind='barh', ax=ax3, title='Count of card4 fraud')\n",
    "train_0.groupby('card4')['card4'].count().plot(kind='barh', ax=ax4, title='Count of card4 non-fraud')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 8))\n",
    "train_1.groupby('card5')['card5'].count().plot(kind='barh', ax=ax1, title='Count of card5 fraud')\n",
    "train_0.groupby('card5')['card5'].count().plot(kind='barh', ax=ax2, title='Count of card5 non-fraud')\n",
    "train_1.groupby('card6')['card6'].count().plot(kind='barh', ax=ax3, title='Count of card6 fraud')\n",
    "train_0.groupby('card6')['card6'].count().plot(kind='barh', ax=ax4, title='Count of card6 non-fraud')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.preprocessing import Imputer, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, Y_train, Y_val = train_test_split(X_train, y_train, \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, Y_train)\n",
    "y_pred = rf.predict(X_val)\n",
    "acc = np.mean(Y_val == y_pred )\n",
    "print(\"SKLEARN Random Forest Accuracy = {:3.3f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(train1.drop(columns=['isFraud']))\n",
    "y=np.array(pd.get_dummies(train1.isFraud))\n",
    "headerX = train1.drop(columns=['isFraud']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_val, y_train1, y_val = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "n_train_size = y_train1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40\n",
    "n_batches  = 10000\n",
    "learn_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 계층!\n",
    "W1 = tf.Variable(tf.random_normal([19,9],0,1))   # 입력 = 19, 출력 = 10.\n",
    "b1 = tf.Variable(tf.random_normal([9],0,1))     \n",
    "W2 = tf.Variable(tf.random_normal([9,2],0,1))   # 입력 = 10, 출력 = 2.\n",
    "b2 = tf.Variable(tf.random_normal([2],0,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ph = tf.placeholder(tf.float32, [None, 19]) # 행의 개수 미정 (None).\n",
    "y_ph = tf.placeholder(tf.float32,[None,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 모형 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 계층!\n",
    "hidden = tf.nn.sigmoid(tf.matmul(X_ph,W1) + b1)\n",
    "y_model = tf.matmul(hidden, W2) + b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 손실함수 정의, 최적화 방법 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss  = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_ph, logits=y_model))   # loss = Cross Entropy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate = learn_rate) \n",
    "#optimizer = tf.train.MomentumOptimizer(learning_rate = learn_rate, momentum=0.8) \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learn_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable 전역 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session을 시작해서 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for i in range(n_batches):\n",
    "            idx_rnd = np.random.randint(0,n_train_size,batch_size)\n",
    "            batch_X, batch_y = [X_train1[idx_rnd,:], y_train1[idx_rnd,:]]\n",
    "            my_feed = {X_ph:batch_X, y_ph:batch_y}\n",
    "            sess.run(train, feed_dict = my_feed)\n",
    "            if (i + 1) % 2000 == 0: print(i + 1)\n",
    "        # 모형 평가.\n",
    "        correct_predictions = tf.equal(tf.argmax(y_ph, 1), tf.argmax(y_model, 1))      # Axis=1는 가로 방향 argmax().\n",
    "        acc = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))                 # 먼저 boolean을 float32로 cast.\n",
    "        acc_value = sess.run(acc, feed_dict={X_ph:X_val, y_ph:y_val})   # 시험 데이터 전체."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"정확도 = {:5.3f}\".format(acc_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
